{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d8e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\MONSTER\\Desktop\\YILBAŞI PROJEM - Kopya\n"
     ]
    }
   ],
   "source": [
    "# Log Transformation yapılabilir.\n",
    "# total_cases sağa çarpık (skewed) → log bunu düzeltir\n",
    "# XGBoost ve RandomForest log dönüşümüyle daha stabil öğrenir\n",
    "# Büyük vakalar (100–400) çok ağırlık bindirmesin diye log dengeler\n",
    "import os, sys\n",
    "\n",
    "# notebook içindeyken proje köküne çık\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df82d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\1568005869.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_sj = df_sj.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\1568005869.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_iq = df_iq.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>1990-05-07</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>1990-05-14</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>1990-05-21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>1990-05-28</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "0   sj  1990          18      1990-04-30  0.122600  0.103725  0.198483   \n",
       "1   sj  1990          19      1990-05-07  0.169900  0.142175  0.162357   \n",
       "2   sj  1990          20      1990-05-14  0.032250  0.172967  0.157200   \n",
       "3   sj  1990          21      1990-05-21  0.128633  0.245067  0.227557   \n",
       "4   sj  1990          22      1990-05-28  0.196200  0.262200  0.251200   \n",
       "\n",
       "    ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "0  0.177617                 12.42             297.572857  ...   \n",
       "1  0.155486                 22.82             298.211429  ...   \n",
       "2  0.170843                 34.54             298.781429  ...   \n",
       "3  0.235886                 15.36             298.987143  ...   \n",
       "4  0.247340                  7.52             299.518571  ...   \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             73.365714                         12.42   \n",
       "1                             77.368571                         22.82   \n",
       "2                             82.052857                         34.54   \n",
       "3                             80.337143                         15.36   \n",
       "4                             80.460000                          7.52   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  \n",
       "0                20.0               16.0            4  \n",
       "1                22.2                8.6            5  \n",
       "2                22.8               41.4            4  \n",
       "3                23.3                4.0            3  \n",
       "4                23.9                5.8            6  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Veriyi yükle (Data/ yok, direkt dosya isimleri)\n",
    "train_features = pd.read_csv(\"Data/dengue_features_train.csv\")\n",
    "train_labels = pd.read_csv(\"Data/dengue_labels_train.csv\")\n",
    "test_features = pd.read_csv(\"Data/dengue_features_test.csv\")\n",
    "\n",
    "# 2) Feature + label tek tabloda birleştir\n",
    "df = train_features.merge(train_labels, on=[\"city\", \"year\", \"weekofyear\"])\n",
    "\n",
    "# 3) Şehir bazında ayır, zaman sırasına göre sırala\n",
    "df_sj = df[df[\"city\"] == \"sj\"].sort_values([\"year\", \"weekofyear\"]).reset_index(drop=True)\n",
    "df_iq = df[df[\"city\"] == \"iq\"].sort_values([\"year\", \"weekofyear\"]).reset_index(drop=True)\n",
    "\n",
    "# 4) Eksikleri forward-fill + backward-fill ile doldur\n",
    "df_sj = df_sj.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "df_iq = df_iq.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "# 5) Tek bir temiz dataframe isterse tekrar birleştir\n",
    "df_clean = pd.concat([df_sj, df_iq], axis=0).sort_values([\"year\", \"weekofyear\"])\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e738ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "      <th>cases_lag_1</th>\n",
       "      <th>cases_lag_2</th>\n",
       "      <th>cases_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_cases  cases_lag_1  cases_lag_2  cases_lag_3\n",
       "0            4          NaN          NaN          NaN\n",
       "1            5          4.0          NaN          NaN\n",
       "2            4          5.0          4.0          NaN\n",
       "3            3          4.0          5.0          4.0\n",
       "4            6          3.0          4.0          5.0\n",
       "5            2          6.0          3.0          4.0\n",
       "6            4          2.0          6.0          3.0\n",
       "7            5          4.0          2.0          6.0\n",
       "8           10          5.0          4.0          2.0\n",
       "9            6         10.0          5.0          4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1, 2, 3 hafta gecikmeli vaka sayıları\n",
    "# Dengue bir zaman serisi ve bugünkü vaka sayısını en çok:\n",
    "# 1 hafta önceki vaka\n",
    "# 2 hafta önceki vaka\n",
    "# 3 hafta önceki vaka\n",
    "# belirliyor. O yüzden bunları feature olarak eklemek puanı ciddi düşürüyor.\n",
    "for lag in [1, 2, 3]:\n",
    "    df_sj[f\"cases_lag_{lag}\"] = df_sj[\"total_cases\"].shift(lag)\n",
    "    df_iq[f\"cases_lag_{lag}\"] = df_iq[\"total_cases\"].shift(lag)\n",
    "\n",
    "df_sj[[\"total_cases\", \"cases_lag_1\", \"cases_lag_2\", \"cases_lag_3\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65321219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>cases_lag_1</th>\n",
       "      <th>cases_lag_2</th>\n",
       "      <th>cases_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>2000-07-22</td>\n",
       "      <td>0.227729</td>\n",
       "      <td>0.145429</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.200314</td>\n",
       "      <td>5.60</td>\n",
       "      <td>295.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>9.114286</td>\n",
       "      <td>25.766667</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>2000-07-29</td>\n",
       "      <td>0.328643</td>\n",
       "      <td>0.322129</td>\n",
       "      <td>0.254371</td>\n",
       "      <td>0.361043</td>\n",
       "      <td>62.76</td>\n",
       "      <td>296.432857</td>\n",
       "      <td>...</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>33.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>0.205529</td>\n",
       "      <td>0.190757</td>\n",
       "      <td>0.231671</td>\n",
       "      <td>0.255314</td>\n",
       "      <td>16.24</td>\n",
       "      <td>297.191429</td>\n",
       "      <td>...</td>\n",
       "      <td>13.771429</td>\n",
       "      <td>25.340000</td>\n",
       "      <td>10.940000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>0.329986</td>\n",
       "      <td>0.380586</td>\n",
       "      <td>0.387271</td>\n",
       "      <td>89.37</td>\n",
       "      <td>297.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.471429</td>\n",
       "      <td>27.016667</td>\n",
       "      <td>11.650000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>72.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>33</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>0.384133</td>\n",
       "      <td>0.392240</td>\n",
       "      <td>0.341780</td>\n",
       "      <td>0.382750</td>\n",
       "      <td>42.08</td>\n",
       "      <td>297.627143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>26.583333</td>\n",
       "      <td>10.316667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>50.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "0   iq  2000          29      2000-07-22  0.227729  0.145429  0.254200   \n",
       "1   iq  2000          30      2000-07-29  0.328643  0.322129  0.254371   \n",
       "2   iq  2000          31      2000-08-05  0.205529  0.190757  0.231671   \n",
       "3   iq  2000          32      2000-08-12  0.312486  0.329986  0.380586   \n",
       "4   iq  2000          33      2000-08-19  0.384133  0.392240  0.341780   \n",
       "\n",
       "    ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "0  0.200314                  5.60             295.357143  ...   \n",
       "1  0.361043                 62.76             296.432857  ...   \n",
       "2  0.255314                 16.24             297.191429  ...   \n",
       "3  0.387271                 89.37             297.320000  ...   \n",
       "4  0.382750                 42.08             297.627143  ...   \n",
       "\n",
       "   reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "0           9.114286           25.766667                10.533333   \n",
       "1           9.500000           26.600000                11.480000   \n",
       "2          13.771429           25.340000                10.940000   \n",
       "3          11.471429           27.016667                11.650000   \n",
       "4          13.700000           26.583333                10.316667   \n",
       "\n",
       "   station_max_temp_c  station_min_temp_c  station_precip_mm  total_cases  \\\n",
       "0                31.5                14.7               30.0            0   \n",
       "1                33.3                19.1                4.0            0   \n",
       "2                32.0                17.0               11.5            0   \n",
       "3                34.0                19.9               72.9            0   \n",
       "4                33.0                20.5               50.1            0   \n",
       "\n",
       "   cases_lag_1  cases_lag_2  cases_lag_3  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sj = df_sj.dropna().reset_index(drop=True)\n",
    "df_iq = df_iq.dropna().reset_index(drop=True)\n",
    "\n",
    "df_sj.head()\n",
    "df_iq.head()\n",
    "#NaN olanları düşürüyoruz çünkü lag feature'lar nedeniyle başta NaN oluştu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5096e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi sıradaki adım → Rolling (hareketli ortalama) feature’ları eklemek.\n",
    "# Sivrisinek popülasyonu ani bile değişmez, birkaç haftalık birikim etkisi vardır.\n",
    "# \"Son 3 haftanın ortalama sıcaklığı\" → tek bir haftadan çok daha iyi bilgi verir.\n",
    "# Kaggle’daki en iyi çözümlerde mutlaka rolling feature var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b972de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg_roll5</th>\n",
       "      <th>reanalysis_dew_point_temp_k_roll3</th>\n",
       "      <th>reanalysis_dew_point_temp_k_roll5</th>\n",
       "      <th>station_avg_temp_c_roll3</th>\n",
       "      <th>station_avg_temp_c_roll5</th>\n",
       "      <th>reanalysis_max_air_temp_k_roll3</th>\n",
       "      <th>reanalysis_max_air_temp_k_roll5</th>\n",
       "      <th>cases_lag_1</th>\n",
       "      <th>cases_lag_2</th>\n",
       "      <th>cases_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>1990-05-28</td>\n",
       "      <td>0.19620</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>...</td>\n",
       "      <td>16.023429</td>\n",
       "      <td>295.521905</td>\n",
       "      <td>294.586286</td>\n",
       "      <td>27.709524</td>\n",
       "      <td>27.057143</td>\n",
       "      <td>301.266667</td>\n",
       "      <td>300.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>23</td>\n",
       "      <td>1990-06-04</td>\n",
       "      <td>0.19620</td>\n",
       "      <td>0.174850</td>\n",
       "      <td>0.254314</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>9.58</td>\n",
       "      <td>299.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.663429</td>\n",
       "      <td>295.660952</td>\n",
       "      <td>295.273714</td>\n",
       "      <td>28.176190</td>\n",
       "      <td>27.591429</td>\n",
       "      <td>301.900000</td>\n",
       "      <td>301.42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>24</td>\n",
       "      <td>1990-06-11</td>\n",
       "      <td>0.11290</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.205071</td>\n",
       "      <td>0.210271</td>\n",
       "      <td>3.48</td>\n",
       "      <td>299.207143</td>\n",
       "      <td>...</td>\n",
       "      <td>17.035714</td>\n",
       "      <td>295.846190</td>\n",
       "      <td>295.656571</td>\n",
       "      <td>28.157143</td>\n",
       "      <td>27.731429</td>\n",
       "      <td>301.866667</td>\n",
       "      <td>301.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>25</td>\n",
       "      <td>1990-06-18</td>\n",
       "      <td>0.07250</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.151471</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>151.12</td>\n",
       "      <td>299.591429</td>\n",
       "      <td>...</td>\n",
       "      <td>17.261429</td>\n",
       "      <td>296.082857</td>\n",
       "      <td>295.876000</td>\n",
       "      <td>27.966667</td>\n",
       "      <td>28.062857</td>\n",
       "      <td>301.433333</td>\n",
       "      <td>301.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>26</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>0.10245</td>\n",
       "      <td>0.146175</td>\n",
       "      <td>0.125571</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>19.32</td>\n",
       "      <td>299.578571</td>\n",
       "      <td>...</td>\n",
       "      <td>17.484857</td>\n",
       "      <td>296.258571</td>\n",
       "      <td>296.089714</td>\n",
       "      <td>28.038095</td>\n",
       "      <td>28.234286</td>\n",
       "      <td>301.333333</td>\n",
       "      <td>301.66</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear week_start_date  ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "0   sj  1990          22      1990-05-28  0.19620  0.262200  0.251200   \n",
       "1   sj  1990          23      1990-06-04  0.19620  0.174850  0.254314   \n",
       "2   sj  1990          24      1990-06-11  0.11290  0.092800  0.205071   \n",
       "3   sj  1990          25      1990-06-18  0.07250  0.072500  0.151471   \n",
       "4   sj  1990          26      1990-06-25  0.10245  0.146175  0.125571   \n",
       "\n",
       "    ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "0  0.247340                  7.52             299.518571  ...   \n",
       "1  0.181743                  9.58             299.630000  ...   \n",
       "2  0.210271                  3.48             299.207143  ...   \n",
       "3  0.133029                151.12             299.591429  ...   \n",
       "4  0.123600                 19.32             299.578571  ...   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg_roll5  \\\n",
       "0                                    16.023429   \n",
       "1                                    16.663429   \n",
       "2                                    17.035714   \n",
       "3                                    17.261429   \n",
       "4                                    17.484857   \n",
       "\n",
       "   reanalysis_dew_point_temp_k_roll3  reanalysis_dew_point_temp_k_roll5  \\\n",
       "0                         295.521905                         294.586286   \n",
       "1                         295.660952                         295.273714   \n",
       "2                         295.846190                         295.656571   \n",
       "3                         296.082857                         295.876000   \n",
       "4                         296.258571                         296.089714   \n",
       "\n",
       "   station_avg_temp_c_roll3  station_avg_temp_c_roll5  \\\n",
       "0                 27.709524                 27.057143   \n",
       "1                 28.176190                 27.591429   \n",
       "2                 28.157143                 27.731429   \n",
       "3                 27.966667                 28.062857   \n",
       "4                 28.038095                 28.234286   \n",
       "\n",
       "   reanalysis_max_air_temp_k_roll3  reanalysis_max_air_temp_k_roll5  \\\n",
       "0                       301.266667                           300.90   \n",
       "1                       301.900000                           301.42   \n",
       "2                       301.866667                           301.50   \n",
       "3                       301.433333                           301.52   \n",
       "4                       301.333333                           301.66   \n",
       "\n",
       "   cases_lag_1  cases_lag_2  cases_lag_3  \n",
       "0          3.0          4.0          5.0  \n",
       "1          6.0          3.0          4.0  \n",
       "2          2.0          6.0          3.0  \n",
       "3          4.0          2.0          6.0  \n",
       "4          5.0          4.0          2.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- SAN JUAN (SJ) ROLLING FEATURES ---\n",
    "\n",
    "rolling_cols = [\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"station_avg_temp_c\",\n",
    "    \"reanalysis_max_air_temp_k\",\n",
    "]\n",
    "\n",
    "df_sj = df_clean[df_clean[\"city\"] == \"sj\"].copy()\n",
    "\n",
    "# Rollings\n",
    "for col in rolling_cols:\n",
    "    df_sj[f\"{col}_roll3\"] = df_sj[col].rolling(window=3).mean()\n",
    "    df_sj[f\"{col}_roll5\"] = df_sj[col].rolling(window=5).mean()\n",
    "\n",
    "# Lag features (zaten eklemiştin ama tekrar burada yer alsın diye)\n",
    "df_sj[\"cases_lag_1\"] = df_sj[\"total_cases\"].shift(1)\n",
    "df_sj[\"cases_lag_2\"] = df_sj[\"total_cases\"].shift(2)\n",
    "df_sj[\"cases_lag_3\"] = df_sj[\"total_cases\"].shift(3)\n",
    "\n",
    "# NaN temizliği\n",
    "df_sj = df_sj.dropna().reset_index(drop=True)\n",
    "\n",
    "df_sj.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a377a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg_roll5</th>\n",
       "      <th>reanalysis_dew_point_temp_k_roll3</th>\n",
       "      <th>reanalysis_dew_point_temp_k_roll5</th>\n",
       "      <th>reanalysis_min_air_temp_k_roll3</th>\n",
       "      <th>reanalysis_min_air_temp_k_roll5</th>\n",
       "      <th>station_min_temp_c_roll3</th>\n",
       "      <th>station_min_temp_c_roll5</th>\n",
       "      <th>cases_lag_1</th>\n",
       "      <th>cases_lag_2</th>\n",
       "      <th>cases_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>2000-07-29</td>\n",
       "      <td>0.328643</td>\n",
       "      <td>0.322129</td>\n",
       "      <td>0.254371</td>\n",
       "      <td>0.361043</td>\n",
       "      <td>62.76</td>\n",
       "      <td>296.432857</td>\n",
       "      <td>...</td>\n",
       "      <td>16.102000</td>\n",
       "      <td>294.125714</td>\n",
       "      <td>294.584000</td>\n",
       "      <td>290.900000</td>\n",
       "      <td>291.38</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>0.205529</td>\n",
       "      <td>0.190757</td>\n",
       "      <td>0.231671</td>\n",
       "      <td>0.255314</td>\n",
       "      <td>16.24</td>\n",
       "      <td>297.191429</td>\n",
       "      <td>...</td>\n",
       "      <td>15.456000</td>\n",
       "      <td>292.826667</td>\n",
       "      <td>293.892286</td>\n",
       "      <td>289.533333</td>\n",
       "      <td>290.46</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>18.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>0.329986</td>\n",
       "      <td>0.380586</td>\n",
       "      <td>0.387271</td>\n",
       "      <td>89.37</td>\n",
       "      <td>297.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.145714</td>\n",
       "      <td>293.168095</td>\n",
       "      <td>293.584857</td>\n",
       "      <td>290.700000</td>\n",
       "      <td>290.66</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>18.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>33</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>0.384133</td>\n",
       "      <td>0.392240</td>\n",
       "      <td>0.341780</td>\n",
       "      <td>0.382750</td>\n",
       "      <td>42.08</td>\n",
       "      <td>297.627143</td>\n",
       "      <td>...</td>\n",
       "      <td>14.814857</td>\n",
       "      <td>293.180000</td>\n",
       "      <td>293.258857</td>\n",
       "      <td>290.400000</td>\n",
       "      <td>290.26</td>\n",
       "      <td>19.133333</td>\n",
       "      <td>18.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>34</td>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>0.408157</td>\n",
       "      <td>0.322157</td>\n",
       "      <td>0.406714</td>\n",
       "      <td>0.302714</td>\n",
       "      <td>49.22</td>\n",
       "      <td>298.238571</td>\n",
       "      <td>...</td>\n",
       "      <td>14.817429</td>\n",
       "      <td>293.572857</td>\n",
       "      <td>293.280286</td>\n",
       "      <td>291.333333</td>\n",
       "      <td>290.80</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "0   iq  2000          30      2000-07-29  0.328643  0.322129  0.254371   \n",
       "1   iq  2000          31      2000-08-05  0.205529  0.190757  0.231671   \n",
       "2   iq  2000          32      2000-08-12  0.312486  0.329986  0.380586   \n",
       "3   iq  2000          33      2000-08-19  0.384133  0.392240  0.341780   \n",
       "4   iq  2000          34      2000-08-26  0.408157  0.322157  0.406714   \n",
       "\n",
       "    ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "0  0.361043                 62.76             296.432857  ...   \n",
       "1  0.255314                 16.24             297.191429  ...   \n",
       "2  0.387271                 89.37             297.320000  ...   \n",
       "3  0.382750                 42.08             297.627143  ...   \n",
       "4  0.302714                 49.22             298.238571  ...   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg_roll5  \\\n",
       "0                                    16.102000   \n",
       "1                                    15.456000   \n",
       "2                                    15.145714   \n",
       "3                                    14.814857   \n",
       "4                                    14.817429   \n",
       "\n",
       "   reanalysis_dew_point_temp_k_roll3  reanalysis_dew_point_temp_k_roll5  \\\n",
       "0                         294.125714                         294.584000   \n",
       "1                         292.826667                         293.892286   \n",
       "2                         293.168095                         293.584857   \n",
       "3                         293.180000                         293.258857   \n",
       "4                         293.572857                         293.280286   \n",
       "\n",
       "   reanalysis_min_air_temp_k_roll3  reanalysis_min_air_temp_k_roll5  \\\n",
       "0                       290.900000                           291.38   \n",
       "1                       289.533333                           290.46   \n",
       "2                       290.700000                           290.66   \n",
       "3                       290.400000                           290.26   \n",
       "4                       291.333333                           290.80   \n",
       "\n",
       "   station_min_temp_c_roll3  station_min_temp_c_roll5  cases_lag_1  \\\n",
       "0                 18.166667                     19.20          0.0   \n",
       "1                 16.933333                     18.46          0.0   \n",
       "2                 18.666667                     18.28          0.0   \n",
       "3                 19.133333                     18.24          0.0   \n",
       "4                 19.800000                     19.10          0.0   \n",
       "\n",
       "   cases_lag_2  cases_lag_3  \n",
       "0          0.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          0.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- IQUITOS (IQ) ROLLING FEATURES ---\n",
    "\n",
    "df_iq = df_clean[df_clean[\"city\"] == \"iq\"].copy()\n",
    "\n",
    "rolling_cols = [\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\n",
    "    \"station_min_temp_c\",\n",
    "]\n",
    "\n",
    "# Rollings\n",
    "for col in rolling_cols:\n",
    "    df_iq[f\"{col}_roll3\"] = df_iq[col].rolling(window=3).mean()\n",
    "    df_iq[f\"{col}_roll5\"] = df_iq[col].rolling(window=5).mean()\n",
    "\n",
    "# Lag features\n",
    "df_iq[\"cases_lag_1\"] = df_iq[\"total_cases\"].shift(1)\n",
    "df_iq[\"cases_lag_2\"] = df_iq[\"total_cases\"].shift(2)\n",
    "df_iq[\"cases_lag_3\"] = df_iq[\"total_cases\"].shift(3)\n",
    "\n",
    "# NaN temizliği\n",
    "df_iq = df_iq.dropna().reset_index(drop=True)\n",
    "\n",
    "df_iq.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463c393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>4.647232e-01</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>3.546049e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>2.393157e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1.205367e-01</td>\n",
       "      <td>-0.992709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>-3.216245e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekofyear      week_sin  week_cos\n",
       "0          22  4.647232e-01 -0.885456\n",
       "1          23  3.546049e-01 -0.935016\n",
       "2          24  2.393157e-01 -0.970942\n",
       "3          25  1.205367e-01 -0.992709\n",
       "4          26 -3.216245e-16 -1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_seasonal_features(df_city):\n",
    "    week = df_city[\"weekofyear\"]\n",
    "    df_city[\"week_sin\"] = np.sin(2 * np.pi * week / 52)\n",
    "    df_city[\"week_cos\"] = np.cos(2 * np.pi * week / 52)\n",
    "    return df_city\n",
    "\n",
    "df_sj = add_seasonal_features(df_sj)\n",
    "df_iq = add_seasonal_features(df_iq)\n",
    "\n",
    "df_sj[[\"weekofyear\", \"week_sin\", \"week_cos\"]].head()\n",
    "\n",
    "# weekofyear = 1 ve 52 matematiksel olarak birbirine çok yakın ama model için “1 ve 52” gibi gözüküyor.\n",
    "# Bunu düzeltmek için sin/cos ile dönüştürebiliriz.\n",
    "# Hafta numarasının döngüsel yapısını yakalamak için weekofyear değişkenini sinüs ve kosinüs dönüşümleriyle encode ettik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30745637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_temp_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.3</td>\n",
       "      <td>32.2</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_min_temp_c  station_max_temp_c  station_temp_range\n",
       "0                23.9                35.0                11.1\n",
       "1                23.9                34.4                10.5\n",
       "2                23.3                32.2                 8.9\n",
       "3                22.8                33.9                11.1\n",
       "4                22.8                33.9                11.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_temp_range(df_city):\n",
    "    df_city[\"station_temp_range\"] = df_city[\"station_max_temp_c\"] - df_city[\"station_min_temp_c\"]\n",
    "    return df_city\n",
    "\n",
    "df_sj = add_temp_range(df_sj)\n",
    "df_iq = add_temp_range(df_iq)\n",
    "\n",
    "df_sj[[\"station_min_temp_c\", \"station_max_temp_c\", \"station_temp_range\"]].head()\n",
    "\n",
    "# Sıcaklık aralığı (gün içi dalgalanma)\n",
    "# Isı farkı → sivrisinek aktivitesi için önemli olabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a87cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>temp_humidity_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.664286</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>5157.222357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299.764286</td>\n",
       "      <td>17.212857</td>\n",
       "      <td>5159.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299.221429</td>\n",
       "      <td>17.234286</td>\n",
       "      <td>5156.867592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.528571</td>\n",
       "      <td>17.977143</td>\n",
       "      <td>5384.667918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299.557143</td>\n",
       "      <td>17.790000</td>\n",
       "      <td>5329.121571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reanalysis_avg_temp_k  reanalysis_specific_humidity_g_per_kg  \\\n",
       "0             299.664286                              17.210000   \n",
       "1             299.764286                              17.212857   \n",
       "2             299.221429                              17.234286   \n",
       "3             299.528571                              17.977143   \n",
       "4             299.557143                              17.790000   \n",
       "\n",
       "   temp_humidity_interaction  \n",
       "0                5157.222357  \n",
       "1                5159.799827  \n",
       "2                5156.867592  \n",
       "3                5384.667918  \n",
       "4                5329.121571  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_temp_humidity_interaction(df_city):\n",
    "    df_city[\"temp_humidity_interaction\"] = (\n",
    "        df_city[\"reanalysis_avg_temp_k\"] * df_city[\"reanalysis_specific_humidity_g_per_kg\"]\n",
    "    )\n",
    "    return df_city\n",
    "\n",
    "df_sj = add_temp_humidity_interaction(df_sj)\n",
    "df_iq = add_temp_humidity_interaction(df_iq)\n",
    "\n",
    "df_sj[[\"reanalysis_avg_temp_k\", \n",
    "       \"reanalysis_specific_humidity_g_per_kg\", \n",
    "       \"temp_humidity_interaction\"]].head()\n",
    "\n",
    "# Nem tek başına, sıcaklık tek başına yetmeyebilir.\n",
    "# Virüs için asıl önemli olan “sıcak ve nemli” ortam → bunu çarpım ile verebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc6e179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 932 entries, 0 to 931\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   city                                         932 non-null    object \n",
      " 1   year                                         932 non-null    int64  \n",
      " 2   weekofyear                                   932 non-null    int64  \n",
      " 3   week_start_date                              932 non-null    object \n",
      " 4   ndvi_ne                                      932 non-null    float64\n",
      " 5   ndvi_nw                                      932 non-null    float64\n",
      " 6   ndvi_se                                      932 non-null    float64\n",
      " 7   ndvi_sw                                      932 non-null    float64\n",
      " 8   precipitation_amt_mm                         932 non-null    float64\n",
      " 9   reanalysis_air_temp_k                        932 non-null    float64\n",
      " 10  reanalysis_avg_temp_k                        932 non-null    float64\n",
      " 11  reanalysis_dew_point_temp_k                  932 non-null    float64\n",
      " 12  reanalysis_max_air_temp_k                    932 non-null    float64\n",
      " 13  reanalysis_min_air_temp_k                    932 non-null    float64\n",
      " 14  reanalysis_precip_amt_kg_per_m2              932 non-null    float64\n",
      " 15  reanalysis_relative_humidity_percent         932 non-null    float64\n",
      " 16  reanalysis_sat_precip_amt_mm                 932 non-null    float64\n",
      " 17  reanalysis_specific_humidity_g_per_kg        932 non-null    float64\n",
      " 18  reanalysis_tdtr_k                            932 non-null    float64\n",
      " 19  station_avg_temp_c                           932 non-null    float64\n",
      " 20  station_diur_temp_rng_c                      932 non-null    float64\n",
      " 21  station_max_temp_c                           932 non-null    float64\n",
      " 22  station_min_temp_c                           932 non-null    float64\n",
      " 23  station_precip_mm                            932 non-null    float64\n",
      " 24  total_cases                                  932 non-null    int64  \n",
      " 25  reanalysis_specific_humidity_g_per_kg_roll3  932 non-null    float64\n",
      " 26  reanalysis_specific_humidity_g_per_kg_roll5  932 non-null    float64\n",
      " 27  reanalysis_dew_point_temp_k_roll3            932 non-null    float64\n",
      " 28  reanalysis_dew_point_temp_k_roll5            932 non-null    float64\n",
      " 29  station_avg_temp_c_roll3                     932 non-null    float64\n",
      " 30  station_avg_temp_c_roll5                     932 non-null    float64\n",
      " 31  reanalysis_max_air_temp_k_roll3              932 non-null    float64\n",
      " 32  reanalysis_max_air_temp_k_roll5              932 non-null    float64\n",
      " 33  cases_lag_1                                  932 non-null    float64\n",
      " 34  cases_lag_2                                  932 non-null    float64\n",
      " 35  cases_lag_3                                  932 non-null    float64\n",
      " 36  week_sin                                     932 non-null    float64\n",
      " 37  week_cos                                     932 non-null    float64\n",
      " 38  station_temp_range                           932 non-null    float64\n",
      " 39  temp_humidity_interaction                    932 non-null    float64\n",
      "dtypes: float64(35), int64(3), object(2)\n",
      "memory usage: 291.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Zaman temelli split:\n",
    "# ✔ Veri kronolojik\n",
    "# ✔ Test seti = SON 20%\n",
    "# ✔ Train = önceki 80%\n",
    "df_sj.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4bba7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# San Juan subset zaten hazır: df_sj\n",
    "\n",
    "split_index = int(len(df_sj) * 0.8)\n",
    "train_sj = df_sj.iloc[:split_index]\n",
    "test_sj  = df_sj.iloc[split_index:]\n",
    "\n",
    "# Hedef (label)\n",
    "y_train_sj = train_sj[\"total_cases\"]\n",
    "y_test_sj  = test_sj[\"total_cases\"]\n",
    "\n",
    "# Özelliklerden city, week_start_date ve total_cases'i çıkar\n",
    "drop_cols = [\"total_cases\", \"city\", \"week_start_date\"]\n",
    "\n",
    "X_train_sj = train_sj.drop(columns=drop_cols)\n",
    "X_test_sj  = test_sj.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ea4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İquitos dataset\n",
    "split_index = int(len(df_iq) * 0.8)\n",
    "train_iq = df_iq.iloc[:split_index]\n",
    "test_iq  = df_iq.iloc[split_index:]\n",
    "\n",
    "y_train_iq = train_iq[\"total_cases\"]\n",
    "y_test_iq  = test_iq[\"total_cases\"]\n",
    "\n",
    "X_train_iq = train_iq.drop(columns=drop_cols)  # aynı drop_cols iş görür\n",
    "X_test_iq  = test_iq.drop(columns=drop_cols)\n",
    "\n",
    "y_test_iq = test_iq[\"total_cases\"]\n",
    "\n",
    "\n",
    "# split_index” mantığını çok basit anlatayım\n",
    "# Diyelim ki 100 haftalık veri var\n",
    "# %80 train → ilk 80 hafta\n",
    "# %20 test → son 20 hafta\n",
    "# O yüzden zaman temelli bölme yapıyoruz, rastgele değil\n",
    "# iloc[:split_index] → dizinin başından split index’e kadar\n",
    "# iloc[split_index:] → dizinin split index’ten sonuna kadar\n",
    "# train_test_split() ZAMAN SERİSİ İÇİN KULLANILMAZ\n",
    "# Karıştırır → leakage olur → model geleceği görür → yanlış sonuç\n",
    "# ✔ YERİNE:\n",
    "# Veri zaman sırasına göre olsun\n",
    "# split_index = int(len(df) * 0.8)\n",
    "# İlk %80 → TRAIN\n",
    "# Son %20 → TEST\n",
    "# Bu kadar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0559c093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.826803305727302"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_sj, y_train_sj)\n",
    "\n",
    "pred_sj = model.predict(X_test_sj)\n",
    "mae_sj = mean_absolute_error(y_test_sj, pred_sj)\n",
    "\n",
    "mae_sj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "070edf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.566451821190541"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model_iq = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_iq.fit(X_train_iq, y_train_iq)\n",
    "\n",
    "# 5) Tahmin & MAE\n",
    "pred_iq = model_iq.predict(X_test_iq)\n",
    "mae_iq = mean_absolute_error(y_test_iq, pred_iq)\n",
    "\n",
    "mae_iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest için basit hyperparameter tuning \n",
    "# manuel şekilde deneyerek en iyi parametreleri bulma \n",
    "# zaman serisi verisi için iyiymiş\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def train_eval_rf(df_city, params, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    df_city : tek şehir (sj veya iq)\n",
    "    params  : {'n_estimators': .., 'max_depth': .., 'min_samples_leaf': ..}\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) SADECE SAYISAL FEATURE'LAR\n",
    "    drop_cols = [\"total_cases\", \"log_cases\"]  # varsa log_cases'i de çıkar\n",
    "    num_cols = df_city.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [c for c in num_cols if c not in drop_cols]\n",
    "\n",
    "    # 2) Zaman sırasına göre train / test\n",
    "    split_index = int(len(df_city) * split_ratio)\n",
    "    train = df_city.iloc[:split_index]\n",
    "    test  = df_city.iloc[split_index:]\n",
    "\n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train[\"total_cases\"]\n",
    "    X_test  = test[feature_cols]\n",
    "    y_test  = test[\"total_cases\"]\n",
    "\n",
    "    # 3) Model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "    return mae, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f4ca6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== San Juan (sj) RF tuning ===\n",
      "Şehir: sj\n",
      "{'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1}  -> MAE: 6.835476623543054\n",
      "Şehir: sj\n",
      "{'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1}  -> MAE: 6.8268033057273\n",
      "Şehir: sj\n",
      "{'n_estimators': 400, 'max_depth': 14, 'min_samples_leaf': 1}  -> MAE: 6.837949543654768\n",
      "Şehir: sj\n",
      "{'n_estimators': 400, 'max_depth': 12, 'min_samples_leaf': 2}  -> MAE: 6.925337925147608\n",
      "\n",
      "=== Iquitos (iq) RF tuning ===\n",
      "Şehir: iq\n",
      "{'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1}  -> MAE: 4.619481368892068\n",
      "Şehir: iq\n",
      "{'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1}  -> MAE: 4.56645182119054\n",
      "Şehir: iq\n",
      "{'n_estimators': 400, 'max_depth': 14, 'min_samples_leaf': 1}  -> MAE: 4.532552832777934\n",
      "Şehir: iq\n",
      "{'n_estimators': 400, 'max_depth': 12, 'min_samples_leaf': 2}  -> MAE: 4.511001709404989\n",
      "\n",
      "En iyi SJ RF: {'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1} MAE: 6.8268033057273\n",
      "En iyi IQ RF: {'n_estimators': 400, 'max_depth': 12, 'min_samples_leaf': 2} MAE: 4.511001709404989\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter kombinasyonları, Her parametre kombinasyonunu tek tek deniyor\n",
    "\n",
    "param_grid = [\n",
    "    {\"n_estimators\": 200, \"max_depth\": 10, \"min_samples_leaf\": 1},\n",
    "    {\"n_estimators\": 300, \"max_depth\": 12, \"min_samples_leaf\": 1},\n",
    "    {\"n_estimators\": 400, \"max_depth\": 14, \"min_samples_leaf\": 1},\n",
    "    {\"n_estimators\": 400, \"max_depth\": 12, \"min_samples_leaf\": 2},\n",
    "]\n",
    "\n",
    "results_sj = []\n",
    "results_iq = []\n",
    "\n",
    "print(\"=== San Juan (sj) RF tuning ===\")\n",
    "for p in param_grid:\n",
    "    mae, _ = train_eval_rf(df_sj, p)\n",
    "    results_sj.append((p, mae))\n",
    "    print(p, \" -> MAE:\", mae)\n",
    "\n",
    "print(\"\\n=== Iquitos (iq) RF tuning ===\")\n",
    "for p in param_grid:\n",
    "    mae, _ = train_eval_rf(df_iq, p)\n",
    "    results_iq.append((p, mae))\n",
    "    print(p, \" -> MAE:\", mae)\n",
    "\n",
    "# En iyi kombinasyonları bul\n",
    "best_params_sj, best_mae_sj_rf = min(results_sj, key=lambda x: x[1])\n",
    "best_params_iq, best_mae_iq_rf = min(results_iq, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\nEn iyi SJ RF:\", best_params_sj, \"MAE:\", best_mae_sj_rf)\n",
    "print(\"En iyi IQ RF:\", best_params_iq, \"MAE:\", best_mae_iq_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1d596b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95374fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_poly(df_city, feature_cols, degree=2, alpha=1.0, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    feature_cols : sadece seçtiğimiz en anlamlı kolonlar (korelasyondan gelenler + lag)\n",
    "    degree      : polinom derecesi (k)\n",
    "    alpha       : Ridge regularization güç parametresi\n",
    "    \"\"\"\n",
    "    split_index = int(len(df_city) * split_ratio)\n",
    "    train = df_city.iloc[:split_index]\n",
    "    test  = df_city.iloc[split_index:]\n",
    "\n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train[\"total_cases\"]\n",
    "    X_test  = test[feature_cols]\n",
    "    y_test  = test[\"total_cases\"]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"model\", Ridge(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "    return mae, pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d18ce95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Juan Polynomial Regression MAE: 24.384992309735114\n"
     ]
    }
   ],
   "source": [
    "poly_features_sj = [\n",
    "    \"weekofyear\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"station_avg_temp_c\",\n",
    "    \"reanalysis_max_air_temp_k\",\n",
    "    \n",
    "]\n",
    "\n",
    "mae_poly_sj, model_poly_sj = train_eval_poly(\n",
    "    df_sj,\n",
    "    feature_cols=poly_features_sj,\n",
    "    degree=2,    # k=2: hem ana etkiler hem etkileşimler, çok patlamıyor\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "print(\"San Juan Polynomial Regression MAE:\", mae_poly_sj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62ad9ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iquitos Polynomial Regression MAE: 8.416651859754346\n"
     ]
    }
   ],
   "source": [
    "poly_features_iq = [\n",
    "    \"weekofyear\",\n",
    "    \"year\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\n",
    "    \"station_min_temp_c\",\n",
    "]\n",
    "\n",
    "mae_poly_iq, model_poly_iq = train_eval_poly(\n",
    "    df_iq,\n",
    "    feature_cols=poly_features_iq,\n",
    "    degree=2,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "print(\"Iquitos Polynomial Regression MAE:\", mae_poly_iq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8598bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>6.826803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iquitos</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>4.511002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Polynomial(k=2)</td>\n",
       "      <td>24.384992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iquitos</td>\n",
       "      <td>Polynomial(k=2)</td>\n",
       "      <td>8.416652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City            Model        MAE\n",
       "0  San Juan     RandomForest   6.826803\n",
       "1   Iquitos     RandomForest   4.511002\n",
       "2  San Juan  Polynomial(k=2)  24.384992\n",
       "3   Iquitos  Polynomial(k=2)   8.416652"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"City\": [\"San Juan\", \"Iquitos\", \"San Juan\", \"Iquitos\"],\n",
    "    \"Model\": [\"RandomForest\", \"RandomForest\", \"Polynomial(k=2)\", \"Polynomial(k=2)\"],\n",
    "    \"MAE\": [best_mae_sj_rf, best_mae_iq_rf, mae_poly_sj, mae_poly_iq]\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2507090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1) En önemli 5 feature ----\n",
    "top5_sj = [\n",
    "    \"weekofyear\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"station_avg_temp_c\",\n",
    "    \"reanalysis_max_air_temp_k\"\n",
    "]\n",
    "\n",
    "top5_iq = [\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\n",
    "    \"station_min_temp_c\",\n",
    "    \"year\"\n",
    "]\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def rf_with_selected_features(df, selected_cols, split_index):\n",
    "    X = df[selected_cols]\n",
    "    y = df[\"total_cases\"]\n",
    "\n",
    "    X_train = X.iloc[:split_index]\n",
    "    y_train = y.iloc[:split_index]\n",
    "\n",
    "    X_test = X.iloc[split_index:]\n",
    "    y_test = y.iloc[split_index:]\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=12,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8564cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 412)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time-series split index (80% train, 20% test)\n",
    "split_index_sj = int(len(df_sj) * 0.8)\n",
    "split_index_iq = int(len(df_iq) * 0.8)\n",
    "\n",
    "split_index_sj, split_index_iq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c575465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Juan → RF (5 feature) MAE: 26.60577768094125\n"
     ]
    }
   ],
   "source": [
    "mae_sj_5 = rf_with_selected_features(df_sj, top5_sj, split_index_sj)\n",
    "print(\"San Juan → RF (5 feature) MAE:\", mae_sj_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69c73094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iquitos → RF (5 feature) MAE: 10.08302772745902\n"
     ]
    }
   ],
   "source": [
    "mae_iq_5 = rf_with_selected_features(df_iq, top5_iq, split_index_iq)\n",
    "print(\"Iquitos → RF (5 feature) MAE:\", mae_iq_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zaman serisi (time-series) için klasik GridSearchCV veya RandomizedSearchCV kullanmak YANLIŞTIR. \n",
    "#Ama cv=5 (default) → yanlış\n",
    "# ✔ cv=TimeSeriesSplit(...) → doğru GridSearchCV(model, params, cv=TimeSeriesSplit(...))\n",
    "\n",
    "# RandomizedSearchCV de aynı şekilde kullanılabilir\n",
    "# ✖ shuffle=True → yanlış\n",
    "# ✔ cv=TimeSeriesSplit → doğru\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938f6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe5a1035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.536930561065674, 5.173644065856934)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# XGBoost için feature listeleri (AYRI)\n",
    "# =======================\n",
    "\n",
    "drop_cols = [\"total_cases\", \"city\", \"week_start_date\"]\n",
    "\n",
    "# SJ kendi kolonları\n",
    "feature_cols_sj = [c for c in df_sj.columns if c not in drop_cols]\n",
    "\n",
    "# IQ kendi kolonları\n",
    "feature_cols_iq = [c for c in df_iq.columns if c not in drop_cols]\n",
    "\n",
    "len(feature_cols_sj), len(feature_cols_iq)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# SJ ve IQ için zaman serisi train/test bölümü (80% / 20%)\n",
    "# =======================\n",
    "\n",
    "split_index_sj = int(len(df_sj) * 0.8)\n",
    "split_index_iq = int(len(df_iq) * 0.8)\n",
    "\n",
    "split_index_sj, split_index_iq\n",
    "\n",
    "\n",
    "# =======================\n",
    "# XGBoost modeli + MAE hesaplayan fonksiyon\n",
    "# =======================\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def train_eval_xgb(df_city, feature_cols, split_index, params):\n",
    "    \"\"\"\n",
    "    Tek şehir için:\n",
    "    - Time-series split\n",
    "    - XGBoost modeli kurulumu\n",
    "    - MAE hesabı\n",
    "    \"\"\"\n",
    "    train_city = df_city.iloc[:split_index].copy()\n",
    "    test_city  = df_city.iloc[split_index:].copy()\n",
    "    \n",
    "    X_train = train_city[feature_cols]\n",
    "    y_train = train_city[\"total_cases\"]\n",
    "    \n",
    "    X_test  = test_city[feature_cols]\n",
    "    y_test  = test_city[\"total_cases\"]\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_estimators=params.get(\"n_estimators\", 400),\n",
    "        learning_rate=params.get(\"learning_rate\", 0.05),\n",
    "        max_depth=params.get(\"max_depth\", 6),\n",
    "        subsample=params.get(\"subsample\", 0.9),\n",
    "        colsample_bytree=params.get(\"colsample_bytree\", 0.9),\n",
    "        reg_lambda=params.get(\"reg_lambda\", 1.0),\n",
    "        reg_alpha=params.get(\"reg_alpha\", 0.0),\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    mae  = mean_absolute_error(y_test, pred)\n",
    "    \n",
    "    return mae, model\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Parametre seti\n",
    "# =======================\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"reg_alpha\": 0.0,\n",
    "}\n",
    "\n",
    "\n",
    "# =======================\n",
    "# MODELLERİ ÇALIŞTIR\n",
    "# =======================\n",
    "\n",
    "mae_sj_xgb, model_sj_xgb = train_eval_xgb(df_sj, feature_cols_sj, split_index_sj, xgb_params)\n",
    "mae_iq_xgb, model_iq_xgb = train_eval_xgb(df_iq, feature_cols_iq, split_index_iq, xgb_params)\n",
    "\n",
    "mae_sj_xgb, mae_iq_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f5aa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# XGBoost için arama uzayı (makul ve küçük bir alan)\n",
    "param_space = {\n",
    "    \"n_estimators\":      [200, 400, 600],\n",
    "    \"max_depth\":         [3, 4, 5, 6],\n",
    "    \"learning_rate\":     [0.03, 0.05, 0.07, 0.10],\n",
    "    \"subsample\":         [0.7, 0.9, 1.0],\n",
    "    \"colsample_bytree\":  [0.7, 0.9, 1.0],\n",
    "    \"min_child_weight\":  [1, 3, 5],\n",
    "    \"reg_lambda\":        [0.0, 1.0, 5.0],\n",
    "    \"reg_alpha\":         [0.0, 0.1, 0.5],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "544612aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deneme 1 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 3, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 2 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 3, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 3 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 5.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 4 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 3, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 5 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.07, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'reg_lambda': 1.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 6 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 7 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 8 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'reg_lambda': 5.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 9 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'min_child_weight': 3, 'reg_lambda': 1.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 10 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.07, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 11 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 3, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.1}\n",
      "\n",
      "Deneme 12 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 13 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.07, 'subsample': 0.7, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 5.0, 'reg_alpha': 0.1}\n",
      "\n",
      "Deneme 14 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 1.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 15 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 3, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 16 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'reg_lambda': 5.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 17 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 18 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 1.0, 'min_child_weight': 3, 'reg_lambda': 5.0, 'reg_alpha': 0.1}\n",
      "\n",
      "Deneme 19 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 5.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 20 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 5, 'reg_lambda': 5.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 21 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.07, 'subsample': 0.7, 'colsample_bytree': 1.0, 'min_child_weight': 5, 'reg_lambda': 0.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 22 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.9, 'min_child_weight': 3, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 23 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.03, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 5.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 24 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 25 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.07, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 5, 'reg_lambda': 1.0, 'reg_alpha': 0.1}\n",
      "\n",
      "Deneme 26 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'reg_lambda': 1.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 27 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 5.0, 'reg_alpha': 0.0}\n",
      "\n",
      "Deneme 28 / 30  |  Parametreler: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 0.0, 'reg_alpha': 0.1}\n",
      "\n",
      "Deneme 29 / 30  |  Parametreler: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.7, 'min_child_weight': 5, 'reg_lambda': 5.0, 'reg_alpha': 0.5}\n",
      "\n",
      "Deneme 30 / 30  |  Parametreler: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.5}\n",
      "\n",
      "=== En iyi 5 kombinasayon (San Juan) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>mae</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>reg_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sj</td>\n",
       "      <td>6.635477</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sj</td>\n",
       "      <td>6.688135</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sj</td>\n",
       "      <td>6.731521</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sj</td>\n",
       "      <td>6.783543</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sj</td>\n",
       "      <td>6.823045</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city       mae  n_estimators  max_depth  learning_rate  subsample  \\\n",
       "11   sj  6.635477           400          5           0.05        1.0   \n",
       "17   sj  6.688135           400          3           0.03        1.0   \n",
       "20   sj  6.731521           200          4           0.07        0.7   \n",
       "22   sj  6.783543           200          3           0.03        1.0   \n",
       "14   sj  6.823045           200          5           0.10        1.0   \n",
       "\n",
       "    colsample_bytree  min_child_weight  reg_lambda  reg_alpha  \n",
       "11               0.9                 1         0.0        0.0  \n",
       "17               1.0                 3         5.0        0.1  \n",
       "20               1.0                 5         0.0        0.5  \n",
       "22               0.9                 1         5.0        0.0  \n",
       "14               0.9                 3         0.0        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== En iyi 5 kombinasayon (Iquitos) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>mae</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>reg_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.609147</td>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.616080</td>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.660561</td>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.671416</td>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.730450</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city       mae  n_estimators  max_depth  learning_rate  subsample  \\\n",
       "3    iq  4.609147           600          6           0.05        0.9   \n",
       "25   iq  4.616080           600          6           0.03        0.7   \n",
       "21   iq  4.660561           400          6           0.03        0.7   \n",
       "24   iq  4.671416           600          4           0.07        0.9   \n",
       "8    iq  4.730450           400          3           0.05        0.7   \n",
       "\n",
       "    colsample_bytree  min_child_weight  reg_lambda  reg_alpha  \n",
       "3                1.0                 3         0.0        0.0  \n",
       "25               0.7                 1         1.0        0.0  \n",
       "21               0.9                 3         0.0        0.0  \n",
       "24               1.0                 5         1.0        0.1  \n",
       "8                0.9                 3         1.0        0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Param uzayından rastgele N tane kombinasyon seçelim\n",
    "def sample_param_list(space, n_samples=30, seed=42):\n",
    "    random.seed(seed)\n",
    "    keys = list(space.keys())\n",
    "    combos = []\n",
    "    for _ in range(n_samples):\n",
    "        params = {k: random.choice(space[k]) for k in keys}\n",
    "        combos.append(params)\n",
    "    return combos\n",
    "\n",
    "search_params = sample_param_list(param_space, n_samples=30)\n",
    "\n",
    "results_sj = []\n",
    "results_iq = []\n",
    "\n",
    "for i, p in enumerate(search_params, start=1):\n",
    "    print(f\"\\nDeneme {i} / {len(search_params)}  |  Parametreler: {p}\")\n",
    "    \n",
    "    mae_sj, _ = train_eval_xgb(df_sj, feature_cols_sj, split_index_sj, p)\n",
    "    mae_iq, _ = train_eval_xgb(df_iq, feature_cols_iq, split_index_iq, p)\n",
    "    \n",
    "    results_sj.append({\"city\": \"sj\", \"mae\": mae_sj, **p})\n",
    "    results_iq.append({\"city\": \"iq\", \"mae\": mae_iq, **p})\n",
    "\n",
    "print(\"\\n=== En iyi 5 kombinasayon (San Juan) ===\")\n",
    "results_sj_df = pd.DataFrame(results_sj).sort_values(\"mae\").head(5)\n",
    "display(results_sj_df)\n",
    "\n",
    "print(\"\\n=== En iyi 5 kombinasayon (Iquitos) ===\")\n",
    "results_iq_df = pd.DataFrame(results_iq).sort_values(\"mae\").head(5)\n",
    "display(results_iq_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cd7145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Juan için en iyi XGB param: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_weight': 1, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "Iquitos için en iyi XGB param: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 3, 'reg_lambda': 0.0, 'reg_alpha': 0.0}\n",
      "\n",
      "FINAL XGBoost (SJ) MAE: 6.635477066040039\n",
      "FINAL XGBoost (IQ) MAE: 4.609147071838379\n"
     ]
    }
   ],
   "source": [
    "param_names = list(param_space.keys())\n",
    "\n",
    "best_params_sj = results_sj_df.iloc[0][param_names].to_dict()\n",
    "best_params_iq = results_iq_df.iloc[0][param_names].to_dict()\n",
    "\n",
    "print(\"San Juan için en iyi XGB param:\", best_params_sj)\n",
    "print(\"Iquitos için en iyi XGB param:\", best_params_iq)\n",
    "\n",
    "# 🔴 BURADA feature_cols DEĞİL, SJ ve IQ için AYRI LİSTELER KULLAN\n",
    "best_mae_sj_xgb, best_model_sj_xgb = train_eval_xgb(\n",
    "    df_sj, feature_cols_sj, split_index_sj, best_params_sj\n",
    ")\n",
    "\n",
    "best_mae_iq_xgb, best_model_iq_xgb = train_eval_xgb(\n",
    "    df_iq, feature_cols_iq, split_index_iq, best_params_iq\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL XGBoost (SJ) MAE:\", best_mae_sj_xgb)\n",
    "print(\"FINAL XGBoost (IQ) MAE:\", best_mae_iq_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47813b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "def cv_xgb_timeseries(df_city, feature_cols, params, n_splits=5):\n",
    "    X = df_city[feature_cols].values\n",
    "    y = df_city[\"total_cases\"].values\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, pred)\n",
    "        maes.append(mae)\n",
    "\n",
    "        print(f\"Fold {fold} MAE: {mae:.4f}\")\n",
    "\n",
    "    print(f\"\\nOrtalama CV MAE: {np.mean(maes):.4f}\")\n",
    "    return np.mean(maes), maes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2298e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MAE: 28.3747\n",
      "Fold 2 MAE: 13.8215\n",
      "Fold 3 MAE: 7.6291\n",
      "Fold 4 MAE: 4.5859\n",
      "Fold 5 MAE: 7.3132\n",
      "\n",
      "Ortalama CV MAE: 12.3449\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [c for c in df_sj.columns \n",
    "                if c not in [\"total_cases\", \"city\", \"week_start_date\"]]\n",
    "\n",
    "best_params_sj = {\n",
    "    \"n_estimators\": 400,\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"subsample\": 1.0,\n",
    "    \"colsample_bytree\": 1.0,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"reg_lambda\": 5.0,\n",
    "    \"reg_alpha\": 0.1,\n",
    "}\n",
    "\n",
    "cv_mae_sj, fold_maes_sj = cv_xgb_timeseries(df_sj, feature_cols, best_params_sj, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d50efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "En iyi parametreler (SJ): {'subsample': 0.8, 'reg_lambda': 0.0, 'reg_alpha': 0.1, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.03, 'colsample_bytree': 1.0}\n",
      "En iyi CV MAE (SJ): 12.00220365524292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "X_sj = df_sj[feature_cols].values\n",
    "y_sj = df_sj[\"total_cases\"].values\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [300, 400, 500, 600],\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"reg_lambda\": [0.0, 1.0, 5.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.5],\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "search_sj = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=tscv,                       # 🔴 burada TimeSeriesSplit kullanıyoruz\n",
    "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "search_sj.fit(X_sj, y_sj)\n",
    "\n",
    "print(\"En iyi parametreler (SJ):\", search_sj.best_params_)\n",
    "print(\"En iyi CV MAE (SJ):\", -search_sj.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1e485bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "=== IQ En iyi parametreler ===\n",
      "{'subsample': 0.7, 'reg_lambda': 1.0, 'reg_alpha': 0.5, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "=== IQ En iyi CV MAE ===\n",
      "4.938499832153321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Aynı feature columns listesi IQ için de geçerli\n",
    "X_iq = df_iq[feature_cols_iq]\n",
    "y_iq = df_iq[\"total_cases\"]\n",
    "\n",
    "# TimeSeriesSplit (5 fold)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Aynı parametre uzayı\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400, 500, 600],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.07],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"min_child_weight\": [1, 2, 3, 5],\n",
    "    \"reg_lambda\": [0.0, 0.5, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search_iq = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=tscv,\n",
    "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search_iq.fit(X_iq, y_iq)\n",
    "\n",
    "print(\"=== IQ En iyi parametreler ===\")\n",
    "print(search_iq.best_params_)\n",
    "print(\"=== IQ En iyi CV MAE ===\")\n",
    "print(-search_iq.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "824d1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL XGBoost (IQ) MAE: 4.638535022735596\n"
     ]
    }
   ],
   "source": [
    "best_params_iq = search_iq.best_params_\n",
    "\n",
    "# Train / Test split (80/20) — SJ ile aynı mantık\n",
    "split_index_iq = int(len(df_iq) * 0.8)\n",
    "\n",
    "train_iq = df_iq.iloc[:split_index_iq].copy()\n",
    "test_iq  = df_iq.iloc[split_index_iq:].copy()\n",
    "\n",
    "X_train_iq = train_iq[feature_cols_iq]\n",
    "y_train_iq = train_iq[\"total_cases\"]\n",
    "\n",
    "X_test_iq = test_iq[feature_cols_iq]\n",
    "y_test_iq = test_iq[\"total_cases\"]\n",
    "\n",
    "\n",
    "model_iq_final = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    **best_params_iq\n",
    ")\n",
    "\n",
    "model_iq_final.fit(X_train_iq, y_train_iq)\n",
    "pred_iq = model_iq_final.predict(X_test_iq)\n",
    "\n",
    "final_mae_iq = mean_absolute_error(y_test_iq, pred_iq)\n",
    "\n",
    "print(\"FINAL XGBoost (IQ) MAE:\", final_mae_iq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69798f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\691283926.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\691283926.py:62: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\691283926.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_16172\\691283926.py:62: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission hazır: Data/xgb_submission_best.csv\n",
      "İlk 5 satır:\n",
      "  city  year  weekofyear  total_cases\n",
      "0   sj  2008          18            6\n",
      "1   sj  2008          19            5\n",
      "2   sj  2008          20            7\n",
      "3   sj  2008          21           17\n",
      "4   sj  2008          22            9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# =====================================\n",
    "# 1) Veriyi oku\n",
    "# =====================================\n",
    "PATH = \"Data/\"  # klasör ismin farklıysa burayı değiştir\n",
    "\n",
    "features_train = pd.read_csv(PATH + \"dengue_features_train.csv\")\n",
    "labels_train   = pd.read_csv(PATH + \"dengue_labels_train.csv\")\n",
    "features_test  = pd.read_csv(PATH + \"dengue_features_test.csv\")\n",
    "submission     = pd.read_csv(PATH + \"submission_format.csv\")\n",
    "\n",
    "# train = feature + label birleştir\n",
    "train = features_train.merge(labels_train, on=[\"city\", \"year\", \"weekofyear\"])\n",
    "test  = features_test.copy()\n",
    "\n",
    "# =====================================\n",
    "# 2) Feature engineering (train + test)\n",
    "# =====================================\n",
    "\n",
    "rolling_cols = [\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"station_avg_temp_c\",\n",
    "    \"reanalysis_max_air_temp_k\",\n",
    "]\n",
    "\n",
    "def add_features(df):\n",
    "    # Zaman sırasına göre sırala\n",
    "    df = df.sort_values([\"city\", \"year\", \"weekofyear\"]).reset_index(drop=True)\n",
    "\n",
    "    # Eksik değer doldurma\n",
    "    df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    # Şehir bazlı rolling + ek featurelar\n",
    "    for city_code in [\"sj\", \"iq\"]:\n",
    "        mask = df[\"city\"] == city_code\n",
    "        df_c = df.loc[mask].copy()\n",
    "\n",
    "        # Rolling ortalamalar\n",
    "        for col in rolling_cols:\n",
    "            df_c[f\"{col}_roll3\"] = df_c[col].rolling(window=3, min_periods=1).mean()\n",
    "            df_c[f\"{col}_roll5\"] = df_c[col].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "        # Sıcaklık aralığı\n",
    "        df_c[\"station_temp_range\"] = (\n",
    "            df_c[\"station_max_temp_c\"] - df_c[\"station_min_temp_c\"]\n",
    "        )\n",
    "\n",
    "        # Sıcaklık * nem etkileşimi\n",
    "        df_c[\"temp_humidity_interaction\"] = (\n",
    "            df_c[\"reanalysis_avg_temp_k\"]\n",
    "            * df_c[\"reanalysis_specific_humidity_g_per_kg\"]\n",
    "        )\n",
    "\n",
    "        # Şehir için geri yaz\n",
    "        df.loc[mask, df_c.columns] = df_c\n",
    "\n",
    "    # Rolling’den gelen ufak NaN’leri yine dolduralım\n",
    "    df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    return df\n",
    "\n",
    "train_fe = add_features(train)\n",
    "test_fe  = add_features(test)\n",
    "\n",
    "# =====================================\n",
    "# 3) XGBoost – en iyi parametreler\n",
    "#    (RandomizedSearch + TimeSeriesSplit ile bulduklarımız)\n",
    "# =====================================\n",
    "\n",
    "best_params_sj = {\n",
    "    \"n_estimators\": 400,\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"subsample\": 1.0,\n",
    "    \"colsample_bytree\": 1.0,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"reg_lambda\": 5.0,\n",
    "    \"reg_alpha\": 0.1,\n",
    "}\n",
    "\n",
    "best_params_iq = {\n",
    "    \"n_estimators\": 600,\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"subsample\": 1.0,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"reg_lambda\": 0.0,\n",
    "    \"reg_alpha\": 0.0,\n",
    "}\n",
    "\n",
    "def fit_predict_city(city_code, params):\n",
    "    # Şehir filtrele + zaman sırasına göre sırala\n",
    "    train_c = train_fe[train_fe[\"city\"] == city_code].sort_values(\n",
    "        [\"year\", \"weekofyear\"]\n",
    "    )\n",
    "    test_c = test_fe[test_fe[\"city\"] == city_code].sort_values(\n",
    "        [\"year\", \"weekofyear\"]\n",
    "    )\n",
    "\n",
    "    y = train_c[\"total_cases\"]\n",
    "\n",
    "    # Sadece sayısal kolonları al, target'ı çıkar\n",
    "    num_cols = train_c.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [c for c in num_cols if c != \"total_cases\"]\n",
    "\n",
    "    X_train = train_c[feature_cols]\n",
    "    X_test  = test_c[feature_cols]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    preds = np.maximum(preds, 0)          # negatif olmasın\n",
    "    preds = np.round(preds).astype(int)   # vaka sayısı tam sayı\n",
    "    return preds\n",
    "\n",
    "# Şehir bazlı tahminler\n",
    "sj_preds = fit_predict_city(\"sj\", best_params_sj)\n",
    "iq_preds = fit_predict_city(\"iq\", best_params_iq)\n",
    "\n",
    "# =====================================\n",
    "# 4) Submission dosyasını oluştur\n",
    "#    (Kaggle sırası: önce tüm SJ, sonra tüm IQ)\n",
    "# =====================================\n",
    "\n",
    "all_preds = np.concatenate([sj_preds, iq_preds])\n",
    "submission[\"total_cases\"] = all_preds\n",
    "\n",
    "out_path = PATH + \"xgb_submission_best.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Submission hazır:\", out_path)\n",
    "print(\"İlk 5 satır:\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71770f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>1990-05-07</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>1990-05-14</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>1990-05-21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>1990-05-28</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "0   sj  1990          18      1990-04-30  0.122600  0.103725  0.198483   \n",
       "1   sj  1990          19      1990-05-07  0.169900  0.142175  0.162357   \n",
       "2   sj  1990          20      1990-05-14  0.032250  0.172967  0.157200   \n",
       "3   sj  1990          21      1990-05-21  0.128633  0.245067  0.227557   \n",
       "4   sj  1990          22      1990-05-28  0.196200  0.262200  0.251200   \n",
       "\n",
       "    ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "0  0.177617                 12.42             297.572857  ...   \n",
       "1  0.155486                 22.82             298.211429  ...   \n",
       "2  0.170843                 34.54             298.781429  ...   \n",
       "3  0.235886                 15.36             298.987143  ...   \n",
       "4  0.247340                  7.52             299.518571  ...   \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             73.365714                         12.42   \n",
       "1                             77.368571                         22.82   \n",
       "2                             82.052857                         34.54   \n",
       "3                             80.337143                         15.36   \n",
       "4                             80.460000                          7.52   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  \n",
       "0                20.0               16.0            4  \n",
       "1                22.2                8.6            5  \n",
       "2                22.8               41.4            4  \n",
       "3                23.3                4.0            3  \n",
       "4                23.9                5.8            6  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data import load_raw_data, build_train_dataframe, split_and_clean_by_city\n",
    "\n",
    "train_features, train_labels, test_features = load_raw_data()  # Data otomatik\n",
    "df = build_train_dataframe(train_features, train_labels)\n",
    "df_sj, df_iq = split_and_clean_by_city(df)\n",
    "\n",
    "df_sj.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3043ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJ train shape: (936, 64)\n",
      "SJ test  shape: (260, 64)\n",
      "Feature count: 59\n",
      "Missing in test: [] count: 0\n"
     ]
    }
   ],
   "source": [
    "from src.data import load_raw_data, build_train_dataframe, split_and_clean_by_city\n",
    "from src.features import build_features_city_concat, get_feature_cols\n",
    "\n",
    "train_features, train_labels, test_features = load_raw_data()\n",
    "df = build_train_dataframe(train_features, train_labels)\n",
    "\n",
    "# şehir bazında train ayır\n",
    "df_sj, df_iq = split_and_clean_by_city(df)\n",
    "\n",
    "# test'i şehir bazında ayır\n",
    "test_sj = test_features[test_features[\"city\"]==\"sj\"].sort_values([\"year\",\"weekofyear\"]).reset_index(drop=True)\n",
    "test_iq = test_features[test_features[\"city\"]==\"iq\"].sort_values([\"year\",\"weekofyear\"]).reset_index(drop=True)\n",
    "\n",
    "# feature üret\n",
    "tr_sj, te_sj = build_features_city_concat(df_sj, test_sj, include_cases_lags=False)\n",
    "feat_cols_sj = get_feature_cols(tr_sj)\n",
    "\n",
    "print(\"SJ train shape:\", tr_sj.shape)\n",
    "print(\"SJ test  shape:\", te_sj.shape)\n",
    "print(\"Feature count:\", len(feat_cols_sj))\n",
    "\n",
    "# uyum kontrolü\n",
    "missing_in_test = [c for c in feat_cols_sj if c not in te_sj.columns]\n",
    "print(\"Missing in test:\", missing_in_test[:10], \"count:\", len(missing_in_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
